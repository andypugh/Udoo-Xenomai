***************
*** 19,25 ****
  #include "../kernel/entry-header.S"
  
  	.macro	DBGSTR, str
- #ifdef DEBUG
  	stmfd	sp!, {r0-r3, ip, lr}
  	add	r0, pc, #4
  	bl	printk
--- 19,25 ----
  #include "../kernel/entry-header.S"
  
  	.macro	DBGSTR, str
+ #if defined(DEBUG)
  	stmfd	sp!, {r0-r3, ip, lr}
  	add	r0, pc, #4
  	bl	printk
***************
*** 31,37 ****
  	.endm
  
  	.macro  DBGSTR1, str, arg
- #ifdef DEBUG
  	stmfd	sp!, {r0-r3, ip, lr}
  	mov	r1, \arg
  	add	r0, pc, #4
--- 31,37 ----
  	.endm
  
  	.macro  DBGSTR1, str, arg
+ #if defined(DEBUG)
  	stmfd	sp!, {r0-r3, ip, lr}
  	mov	r1, \arg
  	add	r0, pc, #4
***************
*** 44,50 ****
  	.endm
  
  	.macro  DBGSTR3, str, arg1, arg2, arg3
- #ifdef DEBUG
  	stmfd	sp!, {r0-r3, ip, lr}
  	mov	r3, \arg3
  	mov	r2, \arg2
--- 44,50 ----
  	.endm
  
  	.macro  DBGSTR3, str, arg1, arg2, arg3
+ #if defined(DEBUG)
  	stmfd	sp!, {r0-r3, ip, lr}
  	mov	r3, \arg3
  	mov	r2, \arg2
***************
*** 58,63 ****
  #endif
  	.endm
  
  
  @ VFP hardware support entry point.
  @
--- 58,80 ----
  #endif
  	.endm
  
+ 	.macro TRACE_SAVE, arg
+ #ifdef CONFIG_FPU_TRACE
+ 	stmfd	sp!, {r0-r3, ip, lr}
+ 	mov	r0, \arg
+ 	bl	fp_trace_save
+ 	ldmfd	sp!, {r0-r3, ip, lr}
+ #endif /* CONFIG_FPU_TRACE */
+ 	.endm
+ 
+ 	.macro TRACE_RESTORE, arg
+ #ifdef CONFIG_FPU_TRACE
+ 	stmfd	sp!, {r0-r3, ip, lr}
+ 	mov	r0, \arg
+ 	bl	fp_trace_restore
+ 	ldmfd	sp!, {r0-r3, ip, lr}
+ #endif /* CONFIG_FPU_TRACE */
+ 	.endm
  
  @ VFP hardware support entry point.
  @
***************
*** 77,103 ****
  	bne	look_for_VFP_exceptions	@ VFP is already enabled
  
  	DBGSTR1 "enable %x", r10
- 	ldr	r3, last_VFP_context_address
  	orr	r1, r1, #FPEXC_EN	@ user FPEXC has the enable bit set
- 	ldr	r4, [r3, r11, lsl #2]	@ last_VFP_context pointer
  	bic	r5, r1, #FPEXC_EX	@ make sure exceptions are disabled
- 	cmp	r4, r10
- 	beq	check_for_exception	@ we are returning to the same
- 					@ process, so the registers are
- 					@ still there.  In this case, we do
- 					@ not want to drop a pending exception.
  
  	VFPFMXR	FPEXC, r5		@ enable VFP, disable any pending
  					@ exceptions, so we can get at the
  					@ rest of it
  
- #ifndef CONFIG_SMP
- 	@ Save out the current registers to the old thread state
- 	@ No need for SMP since this is not done lazily
- 
  	DBGSTR1	"save old state %p", r4
- 	cmp	r4, #0
- 	beq	no_old_VFP_process
  	VFPFSTMIA r4, r5		@ save the working registers
  	VFPFMRX	r5, FPSCR		@ current status
  #ifndef CONFIG_CPU_FEROCEON
--- 94,125 ----
  	bne	look_for_VFP_exceptions	@ VFP is already enabled
  
  	DBGSTR1 "enable %x", r10
+ 	ldr	r3, vfp_current_hw_state_address
  	orr	r1, r1, #FPEXC_EN	@ user FPEXC has the enable bit set
+ 	ldr	r4, [r3, r11, lsl #2]	@ vfp_current_hw_state pointer
  	bic	r5, r1, #FPEXC_EX	@ make sure exceptions are disabled
+ 	cmp	r4, r10			@ this thread owns the hw context?
+ #ifndef CONFIG_SMP
+ 	@ For UP, checking that this thread owns the hw context is
+ 	@ sufficient to determine that the hardware state is valid.
+ 	beq	vfp_hw_state_valid
  
+ 	@ On UP, we lazily save the VFP context.  As a different
+ 	@ thread wants ownership of the VFP hardware, save the old
+ 	@ state if there was a previous (valid) owner.
+ 
+ 	enable_irq
+ #ifdef CONFIG_IPIPE
+ 	disable_irq
+ 	ldr	r4, [r3, r11, lsl #2]	@ reload vfp_current_hw_state pointer
+ #endif
  	VFPFMXR	FPEXC, r5		@ enable VFP, disable any pending
  					@ exceptions, so we can get at the
  					@ rest of it
  
  	DBGSTR1	"save old state %p", r4
+ 	cmp	r4, #0			@ if the vfp_current_hw_state is NULL
+ 	beq	vfp_reload_hw		@ then the hw state needs reloading
  	VFPFSTMIA r4, r5		@ save the working registers
  	VFPFMRX	r5, FPSCR		@ current status
  #ifndef CONFIG_CPU_FEROCEON
***************
*** 110,122 ****
  1:
  #endif
  	stmia	r4, {r1, r5, r6, r8}	@ save FPEXC, FPSCR, FPINST, FPINST2
- 					@ and point r4 at the word at the
- 					@ start of the register dump
  #endif
  
- no_old_VFP_process:
  	DBGSTR1	"load state %p", r10
- 	str	r10, [r3, r11, lsl #2]	@ update the last_VFP_context pointer
  					@ Load the saved state back into the VFP
  	VFPFLDMIA r10, r5		@ reload the working registers while
  					@ FPEXC is in a safe state
--- 132,178 ----
  1:
  #endif
  	stmia	r4, {r1, r5, r6, r8}	@ save FPEXC, FPSCR, FPINST, FPINST2
+ vfp_reload_hw:
+ 
+ #else
+ 	@ For SMP, if this thread does not own the hw context, then we
+ 	@ need to reload it.  No need to save the old state as on SMP,
+ 	@ we always save the state when we switch away from a thread.
+ 	bne	vfp_reload_hw
+ 
+ 	@ This thread has ownership of the current hardware context.
+ 	@ However, it may have been migrated to another CPU, in which
+ 	@ case the saved state is newer than the hardware context.
+ 	@ Check this by looking at the CPU number which the state was
+ 	@ last loaded onto.
+ 	ldr	ip, [r10, #VFP_CPU]
+ 	teq	ip, r11
+ 	beq	vfp_hw_state_valid
+ 
+ #if 0
+ vfp_reload_hw:
+ 	enable_irq
+ #ifdef CONFIG_IPIPE
+ 	disable_irq
+ 	mrc     p15, 0, ip, c0, c0, 5  @ reload current CPU number
+ 	and	r11, ip, #15
+ #endif
+ #else
+ vfp_reload_hw:
+ #endif
+ 
+ 	@ We're loading this threads state into the VFP hardware. Update
+ 	@ the CPU number which contains the most up to date VFP context.
+ 	str	r11, [r10, #VFP_CPU]
+ 
+ 	VFPFMXR	FPEXC, r5		@ enable VFP, disable any pending
+ 					@ exceptions, so we can get at the
+ 					@ rest of it
  #endif
  
  	DBGSTR1	"load state %p", r10
+ 	str	r10, [r3, r11, lsl #2]	@ update the vfp_current_hw_state pointer
+ 	TRACE_RESTORE r10
  					@ Load the saved state back into the VFP
  	VFPFLDMIA r10, r5		@ reload the working registers while
  					@ FPEXC is in a safe state
***************
*** 132,144 ****
  #endif
  	VFPFMXR	FPSCR, r5		@ restore status
  
- check_for_exception:
  	tst	r1, #FPEXC_EX
  	bne	process_exception	@ might as well handle the pending
  					@ exception before retrying branch
  					@ out before setting an FPEXC that
  					@ stops us reading stuff
  	VFPFMXR	FPEXC, r1		@ restore FPEXC last
  	sub	r2, r2, #4
  	str	r2, [sp, #S_PC]		@ retry the instruction
  #ifdef CONFIG_PREEMPT
--- 188,202 ----
  #endif
  	VFPFMXR	FPSCR, r5		@ restore status
  
+ @ The context stored in the VFP hardware is up to date with this thread
+ vfp_hw_state_valid:
  	tst	r1, #FPEXC_EX
  	bne	process_exception	@ might as well handle the pending
  					@ exception before retrying branch
  					@ out before setting an FPEXC that
  					@ stops us reading stuff
  	VFPFMXR	FPEXC, r1		@ restore FPEXC last
+ 	enable_irq_cond
  	sub	r2, r2, #4
  	str	r2, [sp, #S_PC]		@ retry the instruction
  #ifdef CONFIG_PREEMPT
***************
*** 164,169 ****
  	@ Fall into hand on to next handler - appropriate coproc instr
  	@ not recognised by VFP
  
  	DBGSTR	"not VFP"
  #ifdef CONFIG_PREEMPT
  	get_thread_info	r10
--- 222,228 ----
  	@ Fall into hand on to next handler - appropriate coproc instr
  	@ not recognised by VFP
  
+ 	enable_irq_cond
  	DBGSTR	"not VFP"
  #ifdef CONFIG_PREEMPT
  	get_thread_info	r10
***************
*** 193,199 ****
  	@ r0 - save location
  	@ r1 - FPEXC
  	DBGSTR1	"save VFP state %p", r0
  	VFPFSTMIA r0, r2		@ save the working registers
  	VFPFMRX	r2, FPSCR		@ current status
  	tst	r1, #FPEXC_EX		@ is there additional state to save?
  	beq	1f
--- 252,260 ----
  	@ r0 - save location
  	@ r1 - FPEXC
  	DBGSTR1	"save VFP state %p", r0
+ 	mov	r3, r0
  	VFPFSTMIA r0, r2		@ save the working registers
+ 	TRACE_SAVE r3
  	VFPFMRX	r2, FPSCR		@ current status
  	tst	r1, #FPEXC_EX		@ is there additional state to save?
  	beq	1f
***************
*** 207,214 ****
  ENDPROC(vfp_save_state)
  
  	.align
- last_VFP_context_address:
- 	.word	last_VFP_context
  
  	.macro	tbl_branch, base, tmp, shift
  #ifdef CONFIG_THUMB2_KERNEL
--- 268,275 ----
  ENDPROC(vfp_save_state)
  
  	.align
+ vfp_current_hw_state_address:
+ 	.word	vfp_current_hw_state
  
  	.macro	tbl_branch, base, tmp, shift
  #ifdef CONFIG_THUMB2_KERNEL
