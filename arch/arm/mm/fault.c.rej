***************
*** 74,79 ****
  	if (!mm)
  		mm = &init_mm;
  
  	printk(KERN_ALERT "pgd = %p\n", mm->pgd);
  	pgd = pgd_offset(mm, addr);
  	printk(KERN_ALERT "[%08lx] *pgd=%08llx",
--- 74,83 ----
  	if (!mm)
  		mm = &init_mm;
  
+ #ifdef CONFIG_ARM_FCSE
+ 	printk(KERN_ALERT "fcse pid: %ld, 0x%08lx\n",
+ 	       mm->context.fcse.pid >> FCSE_PID_SHIFT, mm->context.fcse.pid);
+ #endif /* CONFIG_ARM_FCSE */
  	printk(KERN_ALERT "pgd = %p\n", mm->pgd);
  	pgd = pgd_offset(mm, addr);
  	printk(KERN_ALERT "[%08lx] *pgd=%08llx",
***************
*** 177,187 ****
  	if (user_debug & UDBG_SEGV) {
  		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
  		       tsk->comm, sig, addr, fsr);
  		show_pte(tsk->mm, addr);
  		show_regs(regs);
  	}
  #endif
  
  	tsk->thread.address = addr;
  	tsk->thread.error_code = fsr;
  	tsk->thread.trap_no = 14;
--- 181,201 ----
  	if (user_debug & UDBG_SEGV) {
  		printk(KERN_DEBUG "%s: unhandled page fault (%d) at 0x%08lx, code 0x%03x\n",
  		       tsk->comm, sig, addr, fsr);
+ #ifdef CONFIG_ARM_FCSE_DYNPID
+ 		/* Disable preemption to avoid page tables changing under our
+ 		   feet */
+ 		preempt_disable();
+ #endif /* CONFIG_ARM_FCSE_DYNPID */
  		show_pte(tsk->mm, addr);
+ #ifdef CONFIG_ARM_FCSE_DYNPID
+ 		preempt_enable();
+ #endif /* CONFIG_ARM_FCSE_DYNPID */
  		show_regs(regs);
  	}
  #endif
  
+ 	fcse_notify_segv(tsk->mm, addr, regs);
+ 
  	tsk->thread.address = addr;
  	tsk->thread.error_code = fsr;
  	tsk->thread.trap_no = 14;
***************
*** 284,289 ****
  	if (notify_page_fault(regs, fsr))
  		return 0;
  
  	tsk = current;
  	mm  = tsk->mm;
  
--- 298,306 ----
  	if (notify_page_fault(regs, fsr))
  		return 0;
  
+ 	if (ipipe_trap_notify(IPIPE_TRAP_ACCESS,regs))
+ 		return 0;
+ 
  	tsk = current;
  	mm  = tsk->mm;
  
***************
*** 411,416 ****
  	if (addr < TASK_SIZE)
  		return do_page_fault(addr, fsr, regs);
  
  	if (user_mode(regs))
  		goto bad_area;
  
--- 428,436 ----
  	if (addr < TASK_SIZE)
  		return do_page_fault(addr, fsr, regs);
  
+ 	if (ipipe_trap_notify(IPIPE_TRAP_ACCESS,regs))
+ 		return 0;
+ 
  	if (user_mode(regs))
  		goto bad_area;
  
***************
*** 473,478 ****
  static int
  do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  {
  	do_bad_area(addr, fsr, regs);
  	return 0;
  }
--- 493,502 ----
  static int
  do_sect_fault(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  {
+ 
+ 	if (ipipe_trap_notify(IPIPE_TRAP_SECTION,regs))
+ 		return 0;
+ 
  	do_bad_area(addr, fsr, regs);
  	return 0;
  }
***************
*** 483,488 ****
  static int
  do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  {
  	return 1;
  }
  
--- 507,515 ----
  static int
  do_bad(unsigned long addr, unsigned int fsr, struct pt_regs *regs)
  {
+ 	if (ipipe_trap_notify(IPIPE_TRAP_DABT,regs))
+ 		return 0;
+ 
  	return 1;
  }
  
***************
*** 560,565 ****
  	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
  		return;
  
  	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
  		inf->name, fsr, addr);
  
--- 587,595 ----
  	if (!inf->fn(addr, fsr & ~FSR_LNX_PF, regs))
  		return;
  
+ 	if (ipipe_trap_notify(IPIPE_TRAP_UNKNOWN,regs))
+ 		return;
+ 
  	printk(KERN_ALERT "Unhandled fault: %s (0x%03x) at 0x%08lx\n",
  		inf->name, fsr, addr);
  
***************
*** 660,662 ****
  }
  
  arch_initcall(exceptions_init);
--- 690,739 ----
  }
  
  arch_initcall(exceptions_init);
+ 
+ #ifdef CONFIG_IPIPE
+ extern spinlock_t pgd_lock;
+ extern struct page *pgd_list;
+ 
+ static void vmalloc_sync_one(pgd_t *pgd, unsigned long addr)
+ {
+ 	unsigned int index = pgd_index(addr);
+ 	pgd_t *pgd_k;
+ 	pud_t *pud, *pud_k;
+ 	pmd_t *pmd, *pmd_k;
+ 
+ 	pgd += index;
+ 	pgd_k = init_mm.pgd + index;
+ 
+ 	if (!pgd_present(*pgd))
+ 		set_pgd(pgd, *pgd_k);
+ 
+ 	pud = pud_offset(pgd, addr);
+ 	pud_k = pud_offset(pgd_k, addr);
+ 
+ 	if (!pud_present(*pud))
+ 		set_pud(pud, *pud_k);
+ 
+ 	pmd   = pmd_offset(pud, addr);
+ 	pmd_k = pmd_offset(pud_k, addr);
+ 
+ 	copy_pmd(pmd, pmd_k);
+ }
+ 
+ void __ipipe_pin_range_globally(unsigned long start, unsigned long end)
+ {
+ 	unsigned long next, addr = start;
+ 
+ 	do {
+ 		unsigned long flags;
+ 		struct page *page;
+ 
+ 		next = pgd_addr_end(addr, end);
+ 		spin_lock_irqsave(&pgd_lock, flags);
+ 		for (page = pgd_list; page; page = (struct page *)page->index)
+ 			vmalloc_sync_one(page_address(page), addr);
+ 		spin_unlock_irqrestore(&pgd_lock, flags);
+ 
+ 	} while (addr = next, addr != end);
+ }
+ #endif /* CONFIG_IPIPE */
